{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVSSp4ZFOIsg"
      },
      "source": [
        "# Building your own Chatbot\n",
        "\n",
        "## Why should I build the service again?\n",
        "\n",
        "##### Related: Why can't I use FB/MSFT/some other cloud service?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TarwiiwjOIsk"
      },
      "source": [
        "## Word Vectors + Heuristic - Fancy Stuff = Quick Working Code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy==1.10.1 gensim==4.3.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfhD43rSUIbJ",
        "outputId": "af35583f-d60d-46a1-86e5-df963ef2b145"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
            "Requirement already satisfied: gensim==4.3.2 in /usr/local/lib/python3.11/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scipy==1.10.1) (1.23.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.2) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim==4.3.2) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC7kIWsMOIsk",
        "outputId": "dd2208a0-3ec0-441e-b133-f0b04f63313a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gensim version: 4.3.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gensim\n",
        "print(f\"Gensim version: {gensim.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSHqSU3VOIsl",
        "outputId": "c0665503-dbfc-416d-e59d-6f5afca935e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "glove.6B.zip: 862MB [06:34, 2.18MB/s]                           \n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "class TqdmUpTo(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None: self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "\n",
        "def get_data(url, filename):\n",
        "    \"\"\"\n",
        "    Download data if the filename does not exist already\n",
        "    Uses Tqdm to show download progress\n",
        "    \"\"\"\n",
        "    import os\n",
        "    from urllib.request import urlretrieve\n",
        "\n",
        "    if not os.path.exists(filename):\n",
        "\n",
        "        dirname = os.path.dirname(filename)\n",
        "        if not os.path.exists(dirname):\n",
        "            os.makedirs(dirname)\n",
        "\n",
        "        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n",
        "            urlretrieve(url, filename, reporthook=t.update_to)\n",
        "    else:\n",
        "        print(\"File already exists, please remove if you wish to download again\")\n",
        "\n",
        "embedding_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "get_data(embedding_url, 'data/glove.6B.zip')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip -d data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKUcBvyRhh6u",
        "outputId": "9bed5f8b-f80a-475c-d5e1-fc89e495d08e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-28 20:51:29--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-03-28 20:51:29--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-03-28 20:51:30--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  3.55MB/s    in 5m 34s  \n",
            "\n",
            "2025-03-28 20:57:04 (2.46 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: data/glove.6B.50d.txt   \n",
            "  inflating: data/glove.6B.100d.txt  \n",
            "  inflating: data/glove.6B.200d.txt  \n",
            "  inflating: data/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y1ZgddoOIsm",
        "outputId": "13d0be3a-c7d4-49f3-bb08-fb2e233402f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-e860f5a2409d>:12: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
          ]
        }
      ],
      "source": [
        "# !unzip data/glove.6B.zip\n",
        "# !mv -v glove.6B.300d.txt data/glove.6B.300d.txt\n",
        "# !mv -v glove.6B.200d.txt data/glove.6B.200d.txt\n",
        "# !mv -v glove.6B.100d.txt data/glove.6B.100d.txt\n",
        "# !mv -v glove.6B.50d.txt data/glove.6B.50d.txt\n",
        "\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove_input_file = 'data/glove.6B.300d.txt'\n",
        "word2vec_output_file = 'data/glove.6B.300d.txt.word2vec'\n",
        "import os\n",
        "if not os.path.exists(word2vec_output_file):\n",
        "    glove2word2vec(glove_input_file, word2vec_output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95sudJk_OIsm",
        "outputId": "f511a9e8-9214-4d26-fcd0-ad4df5ed15bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 33s, sys: 2.02 s, total: 1min 35s\n",
            "Wall time: 1min 34s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from gensim.models import KeyedVectors\n",
        "filename = word2vec_output_file\n",
        "embed = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t4zrMVubOIsn"
      },
      "outputs": [],
      "source": [
        "assert embed['awesome'] is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L8zMJwpOIsn"
      },
      "source": [
        "'awesome', this works!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do_P7795OIsn"
      },
      "source": [
        "## Use Case: Food Order Bot\n",
        "\n",
        "### Do word vectors even work for this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YQ5xtbbBOIso"
      },
      "outputs": [],
      "source": [
        "cuisine_refs = [\"mexican\", \"thai\", \"british\", \"american\", \"italian\"]\n",
        "sample_sentence = \"I’m looking for a cheap Indian or Chinese place in Indiranagar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKYSNxTdOIsp",
        "outputId": "77f329b5-d236-44b2-89ff-91351e84dd87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looking: 7.448504447937012\n",
            "for: 10.627421379089355\n",
            "a: 11.80955982208252\n",
            "cheap: 7.096707820892334\n",
            "indian: 18.64516258239746\n",
            "or: 9.692893981933594\n",
            "chinese: 19.09498405456543\n",
            "place: 7.651237487792969\n",
            "in: 10.085711479187012\n",
            "['indian', 'chinese']\n"
          ]
        }
      ],
      "source": [
        "tokens = sample_sentence.split()\n",
        "tokens = [x.lower().strip() for x in tokens]\n",
        "threshold = 18.3\n",
        "found = []\n",
        "for term in tokens:\n",
        "    # Check if the term exists in the KeyedVectors' key_to_index dictionary\n",
        "    if term in embed.key_to_index:\n",
        "        scores = []\n",
        "        for C in cuisine_refs:\n",
        "            scores.append(np.dot(embed[C], embed[term].T))\n",
        "            # hint replace above above np.dot with:\n",
        "            # scores.append(embed.cosine_similarities(<vector1>, <vector_all_others>))\n",
        "        mean_score = np.mean(scores)\n",
        "        print(f\"{term}: {mean_score}\")\n",
        "        if mean_score > threshold:\n",
        "            found.append(term)\n",
        "print(found)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhIS-mQiOIsq"
      },
      "source": [
        "### Next Stop: Classifying user intent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iUaqDUdOIsq",
        "outputId": "8ecac70b-4fd8-43dd-c1a6-2b68c3c2957d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n"
          ]
        }
      ],
      "source": [
        "def sum_vecs(embed,text):\n",
        "\n",
        "    tokens = text.split(' ')\n",
        "    vec = np.zeros(embed.vector_size)\n",
        "\n",
        "    for idx, term in enumerate(tokens):\n",
        "        # Use 'in embed.key_to_index' instead of 'in embed.vocab' to check for term existence\n",
        "        if term in embed.key_to_index:\n",
        "            vec = vec + embed[term]\n",
        "    return vec\n",
        "\n",
        "sentence_vector = sum_vecs(embed, sample_sentence)\n",
        "print(sentence_vector.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-mDGrlidOIsq"
      },
      "outputs": [],
      "source": [
        "data={\n",
        "  \"greet\": {\n",
        "    \"examples\" : [\"hello\",\"hey there\",\"howdy\",\"hello\",\"hi\",\"hey\",\"hey ho\"],\n",
        "    \"centroid\" : None\n",
        "  },\n",
        "  \"inform\": {\n",
        "    \"examples\" : [\n",
        "        \"i'd like something asian\",\n",
        "        \"maybe korean\",\n",
        "        \"what mexican options do i have\",\n",
        "        \"what italian options do i have\",\n",
        "        \"i want korean food\",\n",
        "        \"i want german food\",\n",
        "        \"i want vegetarian food\",\n",
        "        \"i would like chinese food\",\n",
        "        \"i would like indian food\",\n",
        "        \"what japanese options do i have\",\n",
        "        \"korean please\",\n",
        "        \"what about indian\",\n",
        "        \"i want some chicken\",\n",
        "        \"maybe thai\",\n",
        "        \"i'd like something vegetarian\",\n",
        "        \"show me french restaurants\",\n",
        "        \"show me a cool malaysian spot\",\n",
        "        \"where can I get some spicy food\"\n",
        "    ],\n",
        "    \"centroid\" : None\n",
        "  },\n",
        "  \"deny\": {\n",
        "    \"examples\" : [\n",
        "      \"nah\",\n",
        "      \"any other places ?\",\n",
        "      \"anything else\",\n",
        "      \"no thanks\"\n",
        "      \"not that one\",\n",
        "      \"i do not like that place\",\n",
        "      \"something else please\",\n",
        "      \"no please show other options\"\n",
        "    ],\n",
        "    \"centroid\" : None\n",
        "  },\n",
        "    \"affirm\":{\n",
        "        \"examples\":[\n",
        "            \"yeah\",\n",
        "            \"that works\",\n",
        "            \"good, thanks\",\n",
        "            \"this works\",\n",
        "            \"sounds good\",\n",
        "            \"thanks, this is perfect\",\n",
        "            \"just what I wanted\"\n",
        "        ],\n",
        "        \"centroid\": None\n",
        "    }\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8WFjd4oSOIsr"
      },
      "outputs": [],
      "source": [
        "def get_centroid(embed, examples):\n",
        "    C = np.zeros((len(examples),embed.vector_size))\n",
        "    for idx, text in enumerate(examples):\n",
        "        C[idx,:] = sum_vecs(embed,text)\n",
        "\n",
        "    centroid = np.mean(C,axis=0)\n",
        "    assert centroid.shape[0] == embed.vector_size\n",
        "    return centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IS0S30XlOIsr"
      },
      "outputs": [],
      "source": [
        "# Adding Centroid to data dictionary\n",
        "for label in data.keys():\n",
        "    data[label][\"centroid\"] = get_centroid(embed,data[label][\"examples\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWjbm1qhOIsr",
        "outputId": "e76dcb91-104f-43ef-a1c8-f4978d5c3dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "greet: ['hello', 'hey there', 'howdy', 'hello', 'hi', 'hey', 'hey ho']\n",
            "inform: [\"i'd like something asian\", 'maybe korean', 'what mexican options do i have', 'what italian options do i have', 'i want korean food', 'i want german food', 'i want vegetarian food', 'i would like chinese food', 'i would like indian food', 'what japanese options do i have', 'korean please', 'what about indian', 'i want some chicken', 'maybe thai', \"i'd like something vegetarian\", 'show me french restaurants', 'show me a cool malaysian spot', 'where can I get some spicy food']\n",
            "deny: ['nah', 'any other places ?', 'anything else', 'no thanksnot that one', 'i do not like that place', 'something else please', 'no please show other options']\n",
            "affirm: ['yeah', 'that works', 'good, thanks', 'this works', 'sounds good', 'thanks, this is perfect', 'just what I wanted']\n"
          ]
        }
      ],
      "source": [
        "for label in data.keys():\n",
        "    print(f\"{label}: {data[label]['examples']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SCvHngjKOIss"
      },
      "outputs": [],
      "source": [
        "def get_intent(embed,data, text):\n",
        "    intents = list(data.keys())\n",
        "    vec = sum_vecs(embed,text)\n",
        "    scores = np.array([ np.linalg.norm(vec-data[label][\"centroid\"]) for label in intents])\n",
        "    return intents[np.argmin(scores)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDHOdGqMOIss",
        "outputId": "1ea017b1-32a1-4772-84c0-eb013e9691fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text : 'hey ', predicted_label : 'greet'\n",
            "text : 'i am looking for chinese food', predicted_label : 'inform'\n",
            "text : 'not for me', predicted_label : 'deny'\n",
            "text : 'ok, this is good', predicted_label : 'affirm'\n"
          ]
        }
      ],
      "source": [
        "for text in [\"hey \",\"i am looking for chinese food\",\"not for me\", \"ok, this is good\"]:\n",
        "    print(f\"text : '{text}', predicted_label : '{get_intent(embed, data, text)}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkPq7fbjOIst"
      },
      "source": [
        "## Bot Responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lrxcbvInOIst"
      },
      "outputs": [],
      "source": [
        "templates = {\n",
        "        \"utter_greet\": [\"hey there!\", \"Hey! How you doin'? \"],\n",
        "        \"utter_options\": [\"ok, let me check some more\"],\n",
        "        \"utter_goodbye\": [\"Great, I'll go now. Bye bye\", \"bye bye\", \"Goodbye!\"],\n",
        "        \"utter_default\": [\"Sorry, I didn't quite follow\"],\n",
        "        \"utter_confirm\": [\"Got it\", \"Gotcha\", \"Your order is confirmed now\"]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Uzca6VyCOIst"
      },
      "outputs": [],
      "source": [
        "response_map = {\n",
        "    \"greet\": \"utter_greet\",\n",
        "    \"affirm\": \"utter_goodbye\",\n",
        "    \"deny\": \"utter_options\",\n",
        "    \"inform\": \"utter_confirm\",\n",
        "    \"default\": \"utter_default\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DaBsIvhfOIst"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def get_bot_response(bot_response_map, bot_templates, intent):\n",
        "    if intent not in list(response_map):\n",
        "        intent = \"default\"\n",
        "    select_template = bot_response_map[intent]\n",
        "    templates = bot_templates[select_template]\n",
        "    return random.choice(templates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pmtEG8ueOIst",
        "outputId": "4502330f-8d97-44f1-e7da-139caff6bdcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Gotcha'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "user_intent = get_intent(embed, data, \"i want indian food\")\n",
        "get_bot_response(response_map, templates, user_intent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-OH8e2IOIsu"
      },
      "source": [
        "**Better Response Personalisation?**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCCiGlsZOIsu",
        "outputId": "9c88194d-f4c6-4664-f03e-e4780449f2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text : 'hey', intent: greet, bot: hey there!\n",
            "text : 'i am looking for italian food', intent: inform, bot: Gotcha\n",
            "text : 'not for me', intent: deny, bot: ok, let me check some more\n",
            "text : 'ok, this is good', intent: affirm, bot: bye bye\n"
          ]
        }
      ],
      "source": [
        "for text in [\"hey\",\"i am looking for italian food\",\"not for me\", \"ok, this is good\"]:\n",
        "    user_intent = get_intent(embed, data, text)\n",
        "    bot_reply = get_bot_response(response_map, templates, user_intent)\n",
        "    print(f\"text : '{text}', intent: {user_intent}, bot: {bot_reply}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fastAI",
      "language": "python",
      "name": "fastai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
